import torch
import torchvision.transforms as transforms

from app import procrustes_transform 
import joblib
from model import UNet
from util import Dataset
from torch.utils.data import DataLoader

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
svm_model = joblib.load("SVM.joblib")
net = UNet().to(device)
batch_size = 4

input_transforms = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5, std=0.5)
])

dataset_test = Dataset(data_dir='./dataset',
                       transform=input_transforms)
loader_test = DataLoader(dataset_test, batch_size=batch_size,
                         shuffle=False, num_workers=0)

def predict_species(output):
    """
    UNet outputì„ ë°›ì•„ SVMì„ í†µí•´ ê¿€ë²Œ ì•„ì¢…ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜.
    """
    landmarks = extract_landmarks(output)

    if landmarks is None:
        print("ëœë“œë§ˆí¬ë¥¼ ì¶©ë¶„íˆ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # Procrustes ì •ê·œí™” ì ìš©
    landmarks = procrustes_transform(landmarks.reshape(1, -1))

    # SVM ì˜ˆì¸¡ ìˆ˜í–‰
    prediction = svm_model.predict(landmarks)
    probabilities = svm_model.predict_proba(landmarks)

    print(f"ğŸ ì˜ˆì¸¡ëœ ì•„ì¢…: {prediction[0]}")
    print("ğŸ“Š ì˜ˆì¸¡ í™•ë¥ :")
    for species, prob in zip(svm_model.classes_, probabilities[0]):
        print(f" - {species}: {prob:.2%}")

# ì˜ˆì œ: UNet ì¶”ë¡  ê²°ê³¼ë¥¼ ë°›ì•„ SVM ë¶„ë¥˜ ìˆ˜í–‰
with torch.no_grad():
    net.eval()
    for batch, data in enumerate(loader_test, 1):
        input = data['input'].to(device)
        output = net(input)  # UNet ì¶œë ¥ (segmentation map)

        # UNet ì¶œë ¥ ê¸°ë°˜ìœ¼ë¡œ SVM ì˜ˆì¸¡ ì‹¤í–‰
        predict_species(output)