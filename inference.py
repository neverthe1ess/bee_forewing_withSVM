import torch
import numpy as np
import matplotlib.pyplot as plt
import joblib
import os
from PIL import Image

from torch.utils.data import DataLoader
import torchvision.transforms as transforms

from sklearn.metrics import confusion_matrix, accuracy_score
from model import UNet
from util import load
from scipy.spatial import ConvexHull
from sklearn.cluster import KMeans
import seaborn as sns


# 1. ëª¨ë¸ ë¡œë“œ
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
net = UNet().to(device)
optim = torch.optim.Adam(net.parameters(), lr=1e-3)

# U-Net ëª¨ë¸ ë¡œë“œ
ckpt_dir = './checkpoint'
net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)
net.eval()

# SVM ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
model_dir = './saved_models'
svm_model = joblib.load(os.path.join(model_dir, 'svm_model.joblib'))
scaler = joblib.load(os.path.join(model_dir, 'scaler.joblib'))

# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •
input_transforms = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=0.5, std=0.5)
])

# 3. ëœë“œë§ˆí¬ ì¶”ì¶œ í•¨ìˆ˜
def extract_landmarks_kmeans(binary_mask, K=19):
    """
    binary_mask: (H, W) 0/1 ì´ì§„ ë§ˆìŠ¤í¬ (numpy)
    K: ì°¾ê³ ì í•˜ëŠ” êµ°ì§‘(ëœë“œë§ˆí¬) ê°œìˆ˜
    """
    coords = np.argwhere(binary_mask)  # shape=(N, 2)
    num_pixels = coords.shape[0]
    if num_pixels < K:
        return None
    
    kmeans = KMeans(n_clusters=K, random_state=42, n_init='auto')
    kmeans.fit(coords)
    centers = kmeans.cluster_centers_
    centers = np.round(centers).astype(int)  # (K, 2) ì •ìˆ˜ ì¢Œí‘œ (y, x)
    return centers

# 4. ëœë“œë§ˆí¬ ì •ë ¬ í•¨ìˆ˜
def sort_dots(dots):
    """
    dots: (19, 2) í˜•íƒœì˜ ëœë“œë§ˆí¬ ì¢Œí‘œ (y, x)
    xì¢Œí‘œ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    xì¢Œí‘œ í”½ì…€ ì°¨ì´ê°€ 10 ì´í•˜ì¸ ê²½ìš° yì¢Œí‘œë¡œ ì •ë ¬
    """
    sorted_by_x = dots[np.argsort(dots[:, 1])]
    result = np.zeros_like(sorted_by_x)
    current_idx = 0
    
    while current_idx < len(sorted_by_x):
        current_x = sorted_by_x[current_idx, 1]
        similar_x_indices = []
        
        for i in range(current_idx, len(sorted_by_x)):
            if sorted_by_x[i, 1] - current_x <= 10:
                similar_x_indices.append(i)
            else:
                break
        
        if len(similar_x_indices) > 1:
            points_to_sort = sorted_by_x[similar_x_indices]
            sorted_by_y = points_to_sort[np.argsort(points_to_sort[:, 0])]
            result[current_idx:current_idx+len(similar_x_indices)] = sorted_by_y
        else:
            result[current_idx] = sorted_by_x[current_idx]
        
        current_idx += len(similar_x_indices)
    
    return result

# 5. ê°ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_angles_between_nearest_points(dots):
    """
    dots: (19, 2) (y, x) ì¢Œí‘œ
    ê° ì ë§ˆë‹¤ 'ê°€ì¥ ê°€ê¹Œìš´' ë‹¤ë¥¸ ì ì„ ì°¾ê³ ,
    ë‘ ì ì„ ì‡ëŠ” ì„ ê³¼ xì¶• ì‚¬ì´ì˜ ê°ë„(ë„ ë‹¨ìœ„) ê³„ì‚°.
    """
    diff = dots[:, np.newaxis, :] - dots[np.newaxis, :, :]
    distances = np.sqrt(np.sum(diff**2, axis=2))
    np.fill_diagonal(distances, np.inf)
    
    nearest_indices = np.argmin(distances, axis=1)
    nearest_pts = dots[nearest_indices]
    
    dy = nearest_pts[:, 0] - dots[:, 0]
    dx = nearest_pts[:, 1] - dots[:, 1]
    angles = np.degrees(np.arctan2(dy, dx))
    
    return nearest_pts, angles

# 6. ê¸°í•˜í•™ì  íŠ¹ì„± ê³„ì‚° í•¨ìˆ˜
def calculate_geometric_features(dots):
    """
    ìµœì í™”ëœ ê¸°í•˜í•™ì  íŠ¹ì„± ê³„ì‚°
    """
    features = []
    
    # 1. Centroid size
    centroid_point = np.mean(dots, axis=0)
    distances = np.sqrt(np.sum((dots - centroid_point)**2, axis=1))
    centroid_size = np.mean(distances)
    features.append(centroid_size)
      
    return np.array(features)

# 7. ê°ë„ -> sin/cos ë³€í™˜
def convert_angles_to_sin_cos(angles_deg):
    """
    angles_deg: shape=(19,)  # degree
    ê°ë„ 1ê°œì— ëŒ€í•´ [sin, cos] 2ê°œë¡œ í™•ì¥ -> ìµœì¢… 38ì°¨ì›
    """
    rad = np.deg2rad(angles_deg)
    return np.column_stack([np.sin(rad), np.cos(rad)]).flatten()

# 8. ì‹œê°í™” í•¨ìˆ˜
def visualize_landmarks(image, landmarks, prediction):
    """
    ì´ë¯¸ì§€ì™€ ëœë“œë§ˆí¬ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜
    """
    plt.figure(figsize=(10, 8))
    
    # ì´ë¯¸ì§€ ì¤€ë¹„
    if isinstance(image, torch.Tensor):
        img_np = image.numpy()
        if img_np.shape[0] == 1:
            img_np = img_np[0]
        else:
            img_np = np.transpose(img_np, (1, 2, 0))
    else:
        img_np = np.array(image)
    
    # ì´ë¯¸ì§€ í‘œì‹œ
    plt.imshow(img_np, cmap='gray')
    
    # ëœë“œë§ˆí¬ í‘œì‹œ
    if landmarks is not None:
        plt.scatter(landmarks[:,1], landmarks[:,0], s=30, marker='x', c='red')
        for idx, (y, x) in enumerate(landmarks):
            plt.annotate(str(idx), (x, y), xytext=(5, 5), textcoords='offset points', 
                        fontsize=8, color='red')
    
    # ì œëª© ì„¤ì •
    plt.title(f"Predicted: {prediction}")
    plt.show()

# 9. ì¶”ë¡  í•¨ìˆ˜
def predict_species(image):
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ëœë“œë§ˆí¬ ì˜ˆì¸¡ ë° ë¶„ë¥˜
    """
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    if isinstance(image, torch.Tensor):
        image = image.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    else:
        image = torch.from_numpy(image).unsqueeze(0)
    
    # U-Net ì¶”ë¡ 
    with torch.no_grad():
        output = net(image.to(device))
        binarized = (output > 0.5).float()
        mask_2d = binarized[0, 0].cpu().numpy()
    
    # ëœë“œë§ˆí¬ ì¶”ì¶œ
    centers = extract_landmarks_kmeans(mask_2d, K=19)
    if centers is None:
        print("ëœë“œë§ˆí¬ë¥¼ ì¶©ë¶„íˆ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None, None, None
    
    # í”¼ì²˜ ì¶”ì¶œ
    sorted_landmarks = sort_dots(centers)
    _, angles = calculate_angles_between_nearest_points(sorted_landmarks)
    
    # ê¸°ë³¸ í”¼ì²˜
    feature_38 = convert_angles_to_sin_cos(angles)
    
    # ê¸°í•˜í•™ì  íŠ¹ì„±
    geometric_features = calculate_geometric_features(sorted_landmarks)
    
    # ëª¨ë“  í”¼ì²˜ ê²°í•©
    feature_all = np.concatenate([feature_38, geometric_features])
    
    # ìŠ¤ì¼€ì¼ë§ ë° ì˜ˆì¸¡
    feature_scaled = scaler.transform(feature_all.reshape(1, -1))
    prediction = svm_model.predict(feature_scaled)
    probabilities = svm_model.predict_proba(feature_scaled)
    
    return prediction[0], centers, probabilities[0]

# 10. ë©”ì¸ ì¶”ë¡  ë£¨í”„
def main():
    true_labels = []
    predicted_labels = []
    class_list = ["A", "D", "E", "F", "G", "H"]
    class_dict = {"A" : 0, "D" : 1, "E" : 2, "F" : 3, "G": 4, "H": 5}

    print("ì¶”ë¡  ì‹œì‘...")
   
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
    data_dir = './data_test'
    
    # ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
    image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not image_files:
        print(f"Error: {data_dir} ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    for image_file in image_files:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_path = os.path.join(data_dir, image_file)
        image = Image.open(image_path).convert('L')  # í‘ë°±ìœ¼ë¡œ ë³€í™˜
        
        # ì‹¤ì œ ë ˆì´ë¸” ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ ì²« ë²ˆì§¸ ë¬¸ì)
        true_label_name = image_file[0]  # 0-based indexë¡œ ë³€í™˜

        true_label = class_dict[true_label_name]

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image_tensor = input_transforms(image)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction, landmarks, probabilities = predict_species(image_tensor)
        
        if prediction is not None:
            # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            true_labels.append(true_label)
            predicted_labels.append(prediction - 1)  # 0-based indexë¡œ ë³€í™˜

            print(f"\nì´ë¯¸ì§€: {image_file}")
            print(f"ğŸ ì˜ˆì¸¡ëœ ì•„ì¢…: {class_list[prediction - 1]}")
            print("ğŸ“Š ì˜ˆì¸¡ í™•ë¥ :")
            for species, prob in zip(svm_model.classes_, probabilities):
                print(f" - {species}: {prob:.2%}")
            
            # ì‹œê°í™”
            visualize_landmarks(image_tensor, landmarks, prediction)
        else:
            print(f"\nì´ë¯¸ì§€: {image_file}")
            print("âŒ ëœë“œë§ˆí¬ ì¶”ì¶œ ì‹¤íŒ¨")
    
    print("\nì¶”ë¡  ì™„ë£Œ!")

    # ì •í™•ë„ ê³„ì‚°
    accuracy = accuracy_score(true_labels, predicted_labels)
    
    # í˜¼ë™ í–‰ë ¬ ê³„ì‚° ë° ì‹œê°í™”
    cm = confusion_matrix(true_labels, predicted_labels)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_list,
                yticklabels=class_list)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()
    
    print(f"\nì „ì²´ ì •í™•ë„: {accuracy:.2%}")
if __name__ == "__main__":
    main() 
